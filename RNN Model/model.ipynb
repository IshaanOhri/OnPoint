{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fi64aA0FFxcS"
   },
   "outputs": [],
   "source": [
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JUValOzcHtEK"
   },
   "source": [
    "#Import the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {},
    "colab_type": "code",
    "id": "_Jpu8qLEFxcY",
    "outputId": "95968e01-faac-4911-c802-9c008a4e62cf"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import warnings\n",
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnK5o4Z1Fxcj"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Reviews.csv\",nrows=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cjul88oOFxcr"
   },
   "outputs": [],
   "source": [
    "data.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicates\n",
    "data.dropna(axis=0,inplace=True)#dropping na"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0s6IY-x2FxdL"
   },
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XZr-u3OEFxdT"
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "\n",
    "def text_cleaner(text,num):\n",
    "    newString = text.lower()\n",
    "    newString = BeautifulSoup(newString, \"lxml\").text\n",
    "    newString = re.sub(r'\\([^)]*\\)', '', newString)\n",
    "    newString = re.sub('\"','', newString)\n",
    "    newString = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in newString.split(\" \")])    \n",
    "    newString = re.sub(r\"'s\\b\",\"\",newString)\n",
    "    newString = re.sub(\"[^a-zA-Z]\", \" \", newString) \n",
    "    newString = re.sub('[m]{2,}', 'mm', newString)\n",
    "    if(num==0):\n",
    "        tokens = [w for w in newString.split() if not w in stop_words]\n",
    "    else:\n",
    "        tokens=newString.split()\n",
    "    long_words=[]\n",
    "    for i in tokens:\n",
    "        if len(i)>1:                                                 #removing short word\n",
    "            long_words.append(i)   \n",
    "    return (\" \".join(long_words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A2QAeCHWFxdY"
   },
   "outputs": [],
   "source": [
    "#call the function\n",
    "cleaned_text = []\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(text_cleaner(t,0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GsRXocxoFxd-"
   },
   "outputs": [],
   "source": [
    "#call the function\n",
    "cleaned_summary = []\n",
    "for t in data['Summary']:\n",
    "    cleaned_summary.append(text_cleaner(t,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L1zLpnqsFxey"
   },
   "outputs": [],
   "source": [
    "data['cleaned_text']=cleaned_text\n",
    "data['cleaned_summary']=cleaned_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sYK390unFxfA"
   },
   "outputs": [],
   "source": [
    "data.replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MdF76AHHFxgw",
    "outputId": "e3bbe165-4235-482f-bfd4-36a3f1d95290"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x1a54c0d978>,\n",
       "        <matplotlib.axes._subplots.AxesSubplot object at 0x1a55cb2438>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "# populate the lists with sentence lengths\n",
    "for i in data['cleaned_text']:\n",
    "      text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in data['cleaned_summary']:\n",
    "      summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
    "\n",
    "length_df.hist(bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7JRjwdIOFxg3",
    "outputId": "f968be82-c539-471d-ce23-16f18b059ea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9424926998211739\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for i in data['cleaned_summary']:\n",
    "    if(len(i.split())<=8):\n",
    "        cnt=cnt+1\n",
    "print(cnt/len(data['cleaned_summary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZKD5VOWqFxhC"
   },
   "outputs": [],
   "source": [
    "max_text_len=30\n",
    "max_summary_len=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yY0tEJP0FxhI"
   },
   "outputs": [],
   "source": [
    "cleaned_text =np.array(data['cleaned_text'])\n",
    "cleaned_summary=np.array(data['cleaned_summary'])\n",
    "\n",
    "short_text=[]\n",
    "short_summary=[]\n",
    "\n",
    "for i in range(len(cleaned_text)):\n",
    "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
    "        short_text.append(cleaned_text[i])\n",
    "        short_summary.append(cleaned_summary[i])\n",
    "        \n",
    "df=pd.DataFrame({'text':short_text,'summary':short_summary})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EwLUH78CFxhg"
   },
   "outputs": [],
   "source": [
    "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RakakKHcFxhl"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.0001,random_state=0,shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oRHTgX6hFxhq"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer() \n",
    "x_tokenizer.fit_on_texts(list(x_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y8KronV2Fxhx",
    "outputId": "d2eb2f27-fbbc-4e61-9556-3c3ff5e4327b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 66.17787451789056\n",
      "Total Coverage of rare words: 2.793920898836528\n"
     ]
    }
   ],
   "source": [
    "thresh=4\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in x_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J2giEsF3Fxh3"
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "x_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_tr_seq    =   x_tokenizer.texts_to_sequences(x_tr) \n",
    "x_val_seq   =   x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_tr    =   pad_sequences(x_tr_seq,  maxlen=max_text_len, padding='post')\n",
    "x_val   =   pad_sequences(x_val_seq, maxlen=max_text_len, padding='post')\n",
    "\n",
    "#size of vocabulary ( +1 for padding token)\n",
    "x_voc   =  x_tokenizer.num_words + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eRHqyBkBFxiJ"
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer()   \n",
    "y_tokenizer.fit_on_texts(list(y_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yzE5OiRLFxiM",
    "outputId": "7f7a4f89-b088-4847-8172-09e5a2383d0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of rare words in vocabulary: 77.7580628326897\n",
      "Total Coverage of rare words: 5.085856971148981\n"
     ]
    }
   ],
   "source": [
    "thresh=6\n",
    "\n",
    "cnt=0\n",
    "tot_cnt=0\n",
    "freq=0\n",
    "tot_freq=0\n",
    "\n",
    "for key,value in y_tokenizer.word_counts.items():\n",
    "    tot_cnt=tot_cnt+1\n",
    "    tot_freq=tot_freq+value\n",
    "    if(value<thresh):\n",
    "        cnt=cnt+1\n",
    "        freq=freq+value\n",
    "    \n",
    "print(\"% of rare words in vocabulary:\",(cnt/tot_cnt)*100)\n",
    "print(\"Total Coverage of rare words:\",(freq/tot_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-fswLvIgFxiR"
   },
   "outputs": [],
   "source": [
    "#prepare a tokenizer for reviews on training data\n",
    "y_tokenizer = Tokenizer(num_words=tot_cnt-cnt) \n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "y_tr_seq    =   y_tokenizer.texts_to_sequences(y_tr) \n",
    "y_val_seq   =   y_tokenizer.texts_to_sequences(y_val) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_tr    =   pad_sequences(y_tr_seq, maxlen=max_summary_len, padding='post')\n",
    "y_val   =   pad_sequences(y_val_seq, maxlen=max_summary_len, padding='post')\n",
    "\n",
    "#size of vocabulary\n",
    "y_voc  =   y_tokenizer.num_words +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pR8IX9FRFxiY",
    "outputId": "b116cdbd-42c4-4ede-9f6d-46284115393e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47168, 47168)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tokenizer.word_counts['sostok'],len(y_tr)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZ-vW82sFxih"
   },
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_tr)):\n",
    "    cnt=0\n",
    "    for j in y_tr[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_tr=np.delete(y_tr,ind, axis=0)\n",
    "x_tr=np.delete(x_tr,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cx5NISuMFxik"
   },
   "outputs": [],
   "source": [
    "ind=[]\n",
    "for i in range(len(y_val)):\n",
    "    cnt=0\n",
    "    for j in y_val[i]:\n",
    "        if j!=0:\n",
    "            cnt=cnt+1\n",
    "    if(cnt==2):\n",
    "        ind.append(i)\n",
    "\n",
    "y_val=np.delete(y_val,ind, axis=0)\n",
    "x_val=np.delete(x_val,ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zXef38nBFxir",
    "outputId": "7ae99521-46f8-4c6f-9cba-4979deffeee8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 30, 100)      885800      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 30, 300), (N 481200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 30, 300), (N 721200      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    213200      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 30, 300), (N 721200      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 300),  481200      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 300),  180300      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 600)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 2132)   1281332     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,965,432\n",
      "Trainable params: 4,965,432\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K \n",
    "K.clear_session()\n",
    "\n",
    "latent_dim = 300\n",
    "embedding_dim=100\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs = Input(shape=(max_text_len,))\n",
    "\n",
    "#embedding layer\n",
    "enc_emb =  Embedding(x_voc, embedding_dim,trainable=True)(encoder_inputs)\n",
    "\n",
    "#encoder lstm 1\n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#encoder lstm 2\n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#encoder lstm 3\n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#embedding layer\n",
    "dec_emb_layer = Embedding(y_voc, embedding_dim,trainable=True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2)\n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c])\n",
    "\n",
    "# Attention layer\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# Concat attention input and decoder LSTM output\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#dense layer\n",
    "decoder_dense =  TimeDistributed(Dense(y_voc, activation='softmax'))\n",
    "decoder_outputs = decoder_dense(decoder_concat_input)\n",
    "\n",
    "# Define the model \n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lwfi1Fm8Fxiz"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-A3J92MUljB"
   },
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ETnPzA4OFxi3",
    "outputId": "477e374f-7cf2-4d60-f86e-2c49c9cebedb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45987 samples, validate on 5 samples\n",
      "Epoch 1/50\n",
      " 8448/45987 [====>.........................] - ETA: 4:37 - loss: 3.3967"
     ]
    }
   ],
   "source": [
    "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sBX0zZnOFxjW"
   },
   "outputs": [],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9QkrNV-4Fxjt"
   },
   "outputs": [],
   "source": [
    "# Encode the input sequence to get the feature vector\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
    "\n",
    "# Final decoder model\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6f6TTFnBFxj6"
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sostok']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "      \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token!='eostok'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aAUntznIFxj9"
   },
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
    "            newString=newString+reverse_target_word_index[i]+' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString=''\n",
    "    for i in input_seq:\n",
    "        if(i!=0):\n",
    "            newString=newString+reverse_source_word_index[i]+' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BUtQmQTmFxkI",
    "outputId": "f407d9fc-e0cd-4082-98f5-bd1f562dc26f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review: three small dogs one favorite treats feel giving healthy treat please ever stop making pet shape \n",
      "Original summary: great for little dogs \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: love tea like drinking liquid red hate herbal teas taste smell like stuff awesome \n",
      "Original summary: love it \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: actually pretty good little potato best cheese good toast nicely oven like minutes worth \n",
      "Original summary: pretty good \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: happen like foods sweet aid drinks refreshing helped keep away \n",
      "Original summary: great taste not too sweet very refreshing \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: bought pack inexpensive caviar use night decided go use one dip bad could believe odd flavor terrible aftertaste even taste like caviar threw jar away \n",
      "Original summary: ever \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: around amazon looking gifts pleased see favorite sauce order shipped friends favorite love heat tangy also love pineapple go wrong ordering \n",
      "Original summary: best sauce \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: bags chips open received shipment hoping chips open shipment chips amazon otherwise chips good eat salty \n",
      "Original summary: of chips \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: tea flavor whole flavors bucks \n",
      "Original summary: no tea flavor \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: almost pops less cents great children trip \n",
      "Original summary: could no to pop \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: son favorite dinner best seems best protein dinners great protein love love love brand flavor think purchased jars far \n",
      "Original summary: favorite \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: family enough get product several years ago friend daughter eat pancake mix everyone fix thinks outstanding \n",
      "Original summary: best pancakes ever \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: purchased locally many flavors ordered blueberry online try available locally love blueberry well disappointment sweet little blueberry flavor paid would pay locally disappointed \n",
      "Original summary: sugar free \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: must bit soup tastes imagine might taste like spicy food good flavor find case soup flavor burn \n",
      "Original summary: not for me \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: mix vet recommended ingredient food really helped likes always buy amazon cheaper free shipping \n",
      "Original summary: great for \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: tried chips dr oz recommended show healthier potato chip alternative whole family loves found flavor like way better baked style chip try disappointed \n",
      "Original summary: great snack \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: one best chips buy tried kettle varieties many others slight taste jalapeno delicious perfect sandwich alone like addicted chip see \n",
      "Original summary: taste of \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: got item one day sale amazon love single serving portion following plan points plus per serving tasty line special crackers variety nice box last cheddar bbq favorites try \n",
      "Original summary: perfect for \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: love pop chips variety pack fantastic delivered quickly chips filling full flavor way healthier chips \n",
      "Original summary: love pop chips \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: wheat make lot gluten free foods searched local stores could find flour looked amazon finally found packed arrived perfectly fine already using \n",
      "Original summary: great for \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: use like asian dishes least week love product fast shipping usual would buy \n",
      "Original summary: sauce \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: product misleading tomatoes certified tomatoes received \n",
      "Original summary: not really \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: son food allergies really enjoys bars find good taste also nice \n",
      "Original summary: good flavor \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: always try food feed daughter one actually pretty good daughter loves gets excited make \n",
      "Original summary: yum \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: flavor ordered stock long needed decaf received couple good reviews never tasted awful coffee big \n",
      "Original summary: these are absolutely \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: low calorie satisfying soups nice fill want much want hungry hours \n",
      "Original summary: yum \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: used spicy foods spicy doubt much used could take two \n",
      "Original summary: not \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: favorite tea drink year never get tired like others good time day strong still nicely flavorful good balance spicy herbal \n",
      "Original summary: favorite tea \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: fan hot spicy ramen long time enjoy spice love ramen love product bad way expensive amazon per walmart \n",
      "Original summary: tastes great love hot spicy bad price \n",
      "Predicted summary:  good\n",
      "\n",
      "\n",
      "Review: eat bag every single day best tasting good snack everyone least try hooked \n",
      "Original summary: the best snack food \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: ok soup expected love lobster bisque tried many different kinds different one could find lobster guess ok price would never buy brand lobster bisque \n",
      "Original summary: too \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: black tea everyday past years mine tea one favorite brands highly recommend like black tea think going favorite next years \n",
      "Original summary: my cup of tea \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: made vanilla cake mix ok overly bad flavor however disappointed vanilla flavor subtle felt like needed little sweetness child made ate bites \n",
      "Original summary: could have better \n",
      "Predicted summary:  good\n",
      "\n",
      "\n",
      "Review: eat chips saw tried really amazing love cheddar chips really thin crunch delicious flavor recommend \n",
      "Original summary: amazing chips \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: favorite bars ever dark wonderful filling hard find stores save \n",
      "Original summary: best \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: boxes cherry great buy could find cherry store really care flavors \n",
      "Original summary: all cherry could not find it in \n",
      "Predicted summary:  good\n",
      "\n",
      "\n",
      "Review: delicious healthy plus amazon cheaper buy mrs website \n",
      "Original summary: delicious \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: drink delicious tea almost every day yet find anything like market \n",
      "Original summary: love it \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: delivered great healthy potato chips snack bags perfect size great crunch enjoy flavors \n",
      "Original summary: pop chips \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: things low cal oreo creme cookie oreo basically total nothing black crackers sugar want purchase \n",
      "Original summary: these is not \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: hope amazon item always cannot stand brands since got brand price right amazon \n",
      "Original summary: the best \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: always coffee lover brands heart taste clean strong even packaging still heart \n",
      "Original summary: make my \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: plan definitely edible filling since added chicken \n",
      "Original summary: for it is \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: great snack instead potato chips lower calories still delicious ordering \n",
      "Original summary: pop chips love them \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: many different flavors choose ordered brand first time taste wonderful decaf french vanilla could find decided old brand one \n",
      "Original summary: great taste \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: delicious popcorn lost star use hot air popper many popping great flavor great texture tender add anything even though purchased three different flavored thanks \n",
      "Original summary: delicious popcorn \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: decided try based reviews pretty good especially healthy option sure get \n",
      "Original summary: pretty good but will not buy \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: whole earth brand style line dog loves great dogs like human food \n",
      "Original summary: my dog love this \n",
      "Predicted summary:  good\n",
      "\n",
      "\n",
      "Review: best potato chips ever best price ever paid service shipping free \n",
      "Original summary: kettle organic potato chips \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: good expected would pineapple flavor one get idea pineapple \n",
      "Original summary: flavor \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: love product adds flavor water without nasty artificial hope product stay \n",
      "Original summary: refreshing to water \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: green tea good antioxidants never quite taste lemon ginger give nice flavor great add packet water bottle go without bother \n",
      "Original summary: easy and tasty for better \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: tasty convenient bars people celiac disease seem smaller time taste convenience size \n",
      "Original summary: small but good \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: wonderful eat pop chips fan continue tasty healthy flavors good everyone choices \n",
      "Original summary: pop chips great \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: like oreo oreo got try double stuff best side note shipping maybe better \n",
      "Original summary: the \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: husband twizzlers addict bought many times amazon living cannot get country always fresh tasty packed well arrive timely manner \n",
      "Original summary: fresh \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: chips good could stop eating last long reason gave stars instead think bags little hard open sure need make potato chip bag may need hand open much easier \n",
      "Original summary: these are very good \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: love pineapple flavor makes feel like vacation drinking really tastes better pineapple coconut tried \n",
      "Original summary: yummy \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: husband like whole wheat anything liked pizza simple make pizza put pizza sauce cheese great \n",
      "Original summary: pretty good \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: juice actually concentrated advertised juice flavor tried one concentrated expected others concentrated thin guess tart cherry juice tastes like fresh black tart best flavor \n",
      "Original summary: juice \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: dog anything treats buying five pound bag year dry easy put last forever \n",
      "Original summary: yummy treats \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: nothing good service ever since started ordering amazon com keep good work \n",
      "Original summary: so \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: started house started feeding rather buying smaller bags great value cats love food always look forward eating shipped right door cannot go wrong \n",
      "Original summary: great value \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: never seen much grease product like also enough salt entire family use eat \n",
      "Original summary: tasty but \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: us miss twizzlers go back visit someone always stock say yum sell buyer often able buy right \n",
      "Original summary: these in \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: really like product taste great coffee tea lost weight sugar honey agave nectar \n",
      "Original summary: great way the sugar \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: mom kids two hard time finding snack much sodium rd came along introduced find snack low sodium vegetable top organic know free \n",
      "Original summary: healthy snack \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: admit chip addictive really think one gone far literally inside mouth eating surprised still market \n",
      "Original summary: the your \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: true coffee addict never better coffee candy \n",
      "Original summary: the best \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: man say salsa different kinds almost every meal free bottles first bottle friends fridge tasted hooked since dont hot sauce \n",
      "Original summary: great hot sauce and it \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: salt free product purchased chips quite greasy \n",
      "Original summary: potato chips \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: simple chips taste great healthier alternative brands way better anything baked highly recommend \n",
      "Original summary: pop chips variety \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: gravy mix excellent except use water called use milk instead makes better \n",
      "Original summary: wonderful \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: work aid keep bowl desk used buy grocery store could get less online thought good deal found great deal \n",
      "Original summary: for all \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: cannot believe actually decent taste awesome love chips great crunch great amount flavor addicted recommend friends auto keep reorder early since keeps eating \n",
      "Original summary: so delicious \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: four dogs love stuff bite size treat perfect size training dogs like crunch like small enough huge bag make little gift bags friends dogs \n",
      "Original summary: our dogs go for this \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: got food dog allergic corn wheat potatoes flax fish pork time finding food allergic glad found food finally eating put weight little pricey think worth good product \n",
      "Original summary: great for an dog \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: never kettle brand chip like chips great potato flavor flavorful like sweet onion chips better also top great tasting potato chips kettle chips great chips money \n",
      "Original summary: kettle potato chips potato \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: almost cannot stop eating cereal eat breakfast think want something eat really hungry snack healthy long healthy eat cup enjoy \n",
      "Original summary: wonderful for breakfast and \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: soups bit hot water add salads salad dressings add nice somewhat flavor almost dish \n",
      "Original summary: nice to have in the \n",
      "Predicted summary:  good\n",
      "\n",
      "\n",
      "Review: best chips ever great fat calories regular chips come single servings eat whole bag ok great product would highly recommend anyone \n",
      "Original summary: popchips \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: really excited try clam chowder maine wow think might even better \n",
      "Original summary: not great not bad \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: local stocking pleased buy line make french soup stars since quality much bob red mill products star \n",
      "Original summary: great to be to this \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: item fine banana like banana alot smaller also received item packaging great banana come open shipping packing \n",
      "Original summary: not \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: delicious candy outstanding price rich product fortunes inside added great packaging \n",
      "Original summary: what treat \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: saw made decided give try really enjoy flavor adds looking forward trying several dishes thanks \n",
      "Original summary: product \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: tried normal red tea review flavor still tea less color water well well worth every penny \n",
      "Original summary: tasted better than \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: husband beer nut lover looked many could find small bags love large cans \n",
      "Original summary: hard to find \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: good price love keurig trying flavors great probably order end \n",
      "Original summary: pack \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: happy organic golden grind put many things plus make great yogurt cereal whole seed form staple house \n",
      "Original summary: very happy with this \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: idea good flavors ginger chocolate orange honey varieties mix rich flavor sugar expect \n",
      "Original summary: not for \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: good good standard coconut water brand container smaller like taste plain one better ok \n",
      "Original summary: is better \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: delivered product perfect smell dogs love much less expensive dogs even see carrot grain \n",
      "Original summary: good stuff \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: cookies great watch see great really \n",
      "Original summary: best healthy have ever tasted pretty sweet \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: free chips see regular chip cravings remind munchos less greasy try \n",
      "Original summary: healthy and tasty \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: terrible classic sweet tastes like bad spicy sauce restaurant \n",
      "Original summary: of \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: reading good reviews chips admit disappointed perhaps ended bad batch could taste vinegar seemed far many burnt chips bags flavors better going stick brands \n",
      "Original summary: is the vinegar \n",
      "Predicted summary:  good\n",
      "\n",
      "\n",
      "Review: tried quite varieties brand pineapple best light refreshing sure think anything purchase case look forward drinking regular basis thank great value convenience amazon \n",
      "Original summary: best flavor but refreshing \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: sorry everyone likes mix love like going gourmet restaurant waffles taste turn great easy hard us believe seems everyone \n",
      "Original summary: excellent \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: sent bag daughters class share chocolate fresh enjoyed many \n",
      "Original summary: great deal \n",
      "Predicted summary:  great\n",
      "\n",
      "\n",
      "Review: always find french products web markets area made bargain carry nothing bland tasteless flavorful cooking bag mix ever find \n",
      "Original summary: is the best \n",
      "Predicted summary:  great\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,100):\n",
    "    print(\"Review:\",seq2text(x_tr[i]))\n",
    "    print(\"Original summary:\",seq2summary(y_tr[i]))\n",
    "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "How to build own text summarizer using deep learning.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
